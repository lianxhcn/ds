
# A股上市公司数据分析文档

## 一、项目概述

本项目旨在对中国A股上市公司数据进行分析。通过东方财富 API 接口及网页抓取A股上市公司数据，经过数据合并、清洗等预处理步骤，最终对上市公司数量的年度变化、行业分布等多个维度进行统计和分析，为相关研究、投资者市场判断和拟上市公司决策提供参考。

## 二、数据来源

本分析使用的数据来源于东方财富API及网页，通过合规爬虫技术抓取中国A股交易所公开数据。数据包含上市公司基本信息，以CSV格式存储，文件名为 **`data_raw.csv`**，核心字段如下：

| 字段名     | 说明                                      |
|------------|-------------------------------------------|
| 股票代码   | 上市公司唯一标识（如600519）               |
| 股票名称   | 上市公司全称                              |
| 交易所     | 所属交易所（沪市/深市/北交所）             |
| 板块       | 细分板块（如主板/创业板等）                |
| 上市时间   | YYYYMMDD格式数字或字符串                   |
| 最新价     | 最新股票价格（元）                        |
| 东财行业   | 东方财富行业分类                          |
| 证监会行业 | 证监会标准行业分类（如“制造业-食品制造业”） |

## 三、数据清洗

**清洗目标**：确保数据完整性、一致性和准确性，为后续分析奠定基础。将 `data_raw.csv` 处理后存储为 `data_demo.csv`，后续分析基于 `data_demo.csv`，不影响原始数据。

**核心步骤：**

1. **缺失值处理**  
  - 过滤掉 **股票代码、上市时间、交易所** 字段为空的记录  
  - 保留有效数据行，确保分析字段无缺失  

2. **数据类型转换**  
  - **上市时间**：从字符串/数字提取年、月、日，转换为独立数值字段  
    ```python
    上市年份 = 上市时间 // 10000  # 如20230518 → 2023
    上市月份 = (上市时间 // 100) % 100  # → 05
    上市日期 = 上市时间 % 100  # → 18
    ```

3. **数据验证**  
  - 过滤无效日期（如月份>12、日期>31）  
  - 排除异常年份（如上市年份<1900）  

## 四、分析维度

1. **各年度上市公司总数**
  - **深圳交易所**  
    - 主板上市公司数量  
    - 中小板上市公司数量  
    - 创业板上市公司数量  
  - **上海交易所**  
    - 主板上市公司数量  
    - 科创板上市公司数量  
  - **北交所**  
    - 上市公司数量  

  **分析方法**  
  - 按 `上市年份` 和 `交易所` 分组统计  
  - 对比不同板块在各年度的数量变化  

2. **最新年度上市公司行业分布（以2023年为例）**
  - **深圳交易所** 行业分布（如计算机、医药等）  
  - **上海交易所** 行业分布（如金融、能源等）  
  - **北交所** 行业分布（如新材料、信息技术等）  

  **数据处理**  
  - 从 `证监会行业` 字段拆分一级行业（“-”前内容）和二级行业（“-”后内容）  
  - 按 `交易所` 和 `一级行业` 统计公司数量  

3. **扩展 - A股交易所走势及行业分布分析**

  **可视化图表**
  - **上市公司数量年度变化趋势图**  
    - 横轴：上市年份  
    - 纵轴：公司数量  
    - 分交易所绘制折线图，对比增长趋势  
  - **行业分布柱状图/饼图**  
    - 按交易所展示 top 10 行业的公司数量占比  
    - 饼图适用于整体占比分析，柱状图适用于跨行业对比  
  - **行业集中度分析**  
    - 计算各行业公司数量的赫芬达尔指数（HHI）  
    - 识别高集中度行业（如金融、能源）和分散行业（如信息技术）  

## 五、文件说明

- **原始数据文件**：`data_raw.csv`（含未清洗的原始抓取数据）  
- **清洗后数据文件**：`data_demo.csv`（含拆分后的年/月/日字段及行业分级）  
- **文件说明**：
  1. `codes/`  
     存放项目相关的代码文件和脚本，包括数据抓取、清洗、分析等 Jupyter Notebook 文件。
     - `01_data_crawler.ipynb`  
       数据抓取与合并脚本。用于通过东方财富 API 及网页爬虫抓取A股上市公司基础信息和行业分类，并合并保存为原始数据文件 `data_raw.csv`。
     - `02_data_cleaning.ipynb`  
       数据清洗脚本。对原始数据进行缺失值处理、字段拆分、数据类型转换和异常值过滤，输出清洗后的数据文件 `data_demo.csv`。
     - `03_data_analysis.ipynb`  
       数据分析与可视化脚本。对清洗后的数据进行统计分析，生成上市公司数量、行业分布等可视化图表。
  2. `data/`  
    数据文件夹，存放与项目相关的所有数据文件，包括原始数据、清洗后数据及分析结果等。主要文件说明如下：  
    - `data_raw.csv`  
      原始数据文件，内容同上，包含未清洗的上市公司基础信息和行业分类数据。  
    - `data_demo.csv`  
      清洗后数据文件，内容同上，包含拆分后的年/月/日字段、行业分级等。  
    - `industry_data.csv`  
      每个公司的关联行业信息，便于统计和分析行业分布。  
    - `api_data.csv`  
      通过东财API获取的所有上市公司基础信息（不含行业字段），用于补充和比对数据。  
    - `missing_industry.csv`  
      临时存储未匹配到行业的公司信息，方便与 `api_data.csv` 和 `industry_data.csv` 比对，进行行业信息的补充抓取。
  3. `docs/`
    小组介绍和提示语文件，用于存放不同代码的prompt，我方使用的AI助手为豆包
  4. `output/`
    用来存放分析后产出的图片和文档。  
  5. `readme.md`  
     项目说明文档。介绍项目背景、数据来源、处理流程、分析方法和使用说明等。


## 六、使用说明

1. **环境依赖**  
  请确保已安装以下依赖库：  
  ```bash
  pip install pandas bs4 selenium
  ```

2. **数据获取**  
  - 打开并执行 `01_data_crawler.ipynb`，抓取并合并上市公司基础数据与行业分类数据  
  - 保存为 `data_raw.csv`  

3. **运行清洗脚本**  
  - 打开并执行 `02_data_cleaning.ipynb`，进行数据清洗  
  - 输出结果自动保存至 `data_demo.csv`  

4. **数据分析与可视化**  
  - 打开并执行 `03_data_analysis.ipynb`，生成各交易所上市公司数量、最新年度行业分布、A股交易所走势及行业分布分析等可视化图表  

5. **数据分析工具**  
  - 推荐使用 Jupyter Notebook 或 PyCharm 进行后续分析  
  - 可结合 Matplotlib/Seaborn 库生成可视化图表  

## 七、注意事项

1. 本数据仅用于学习和研究，严禁用于商业用途或非法传播。  
2. 数据可能存在时效性，建议定期更新抓取逻辑以获取最新信息。  
3. 行业分类标准可能因政策调整发生变化，分析时需注意分类规则的一致性。  

---

**更新时间**：2025年5月29日  
**作者**：[第四小组]  
**小组成员**：黄伊姿、陈雪华、陈贵斌、刘斌、张翼、徐龙奇、刘谦勋、曾媚、梁培焙

